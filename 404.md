
<html>
<body>

<h1>FSUU - IT 374 - FINALS</h1>
<h3>Author: Ralph Vincent Alfaras</h3>
<h3>Subject: IT 374 - IT 31</h3>
<h2>Title: Finals HDFS</h2>
 
<h4>Hadoop Distributed File System (HDFS)</h4> 

1) HDFS - since hardware failure is common in huge distributions, HDFS focuses on detection of faults beforehand, as well as quick and automatic recovery of fail time is HDFS main goal.

2) HDFS - High Throughput on lowcost machines, can transfer tons and tons of files on a single instance

3) HDFS - running applications in HDFS are huge, Terabyte is a common file size in HDFS. Therefore high aggregate data bandwidth and large scale of nodes in a single cluster is needed on each instance.

4) HDFS has MapReduce application to refrain from data coherency issues when transferring huge data.

5) With huge data transfers in mind, moving the computation is a lot more efficient than moving the actual data, computation is more efficient if it is nearer the data it operates on.

6) Regarding its architecture, HDFS has Master/ Slave architecture. 

7) HDFS cluster has a single NameNode, this is the MASTER in the architecture that manages file system namespace and regulates access to files by clients.

8) NameNode opens, closes, rename files and rename directories. It is responsible for mapping / assigning blocks to DataNodes.

9) DataNode holds one or more BLOCKS. A File is split into one or several BLOCKS. 

10) DataNode receives read and write requests directly from client. With instructions coming from Namenode, DataNode also performs block creation, deletion, and replication.

</body>
</html>
